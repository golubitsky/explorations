- Cache Hit Ratio
  - forces
    - size of cache key space (number of unique keys)
    - size of cache (cache eviction policy)
    - how long objects can be stored in cache (TTL, time to live)
  - use cases
    - high ratio of reads to writes
- HTTP cache
  - read-through cache
    - meant to be intermediate between client and origin server
      - i.e., proxy
      - transparently add caching
    - either return cached resource or fetch data for the client
    - multiple can be chained
  - headers
    - Cache-Control: no-cache, no-store, max-age=0, must-revalidate
      - private
      - public
      - no-store
      - no-cache
      - max-age (maybe don't use; use Expires header instead)
      - no-transform
      - must-revalidate (avoid serving stale objects at client's request)
    - Vary: Accept-Encoding
      - i.e., make sure that compressed and uncompressed objects are cached independently, preventing any encoding errors
  - fresh: as long as expiration time has not passed
    - stale - opposite
  - most common use cases
    - cache forever: static assets (CSS, JS); can be cached forever if using unique file names
    - cache never
    - cache user-specific data
      - Cache-Control: private
  - Types of caches
    - browser cache
    - caching proxies
      - usually installed in a local corporate network or by the Internet service provider (ISP)
      - unable to intercept SSL traffic, because they don't have the certificates to decrypt and encrypt messages
    - reverse proxies
      - your own servers
      - useful to cache web service responses
      - scaling
        - a single box can handle 10,000 RPS
        - Cache key space
          - count of distinct URLs proxy will observe in hour
          - avoid caching per user to prevent polluting cache with objects that cannot be reused
        - Average response TTL
          - try to use objects permanently
          - negotiate longest acceptable TTL with business stakeholders
        - Average size of cached object
          - most difficult to control
          - CSS and JS can be minified
          - HTML can be preprocessed during template rendering to remove whitespace and comments
        - cache eviction policies such as LRU remove unused items
        - concurrency limit or throughput limit
          - Each proxy is an independent clone, sharing nothing with its siblings
          - increase number of proxies and put them behind LB
    - CDNs
      - advantage: at larger geo scale, push content closer to your users
      - implementation
        - create a subdomain s.example.org and generate URLs for all static content
        - configure CDN provider to accept requests on your behalf
        - cache misses are forwarded to your servers and cached for subsequent requests
- Caching application objects
  - cache-aside rather than read-through
    - application needs to be aware of the existence of the object cache
    - actively (rather than transparently) store and retrieve objects
    - independent key-value store
    - simplistic programming interface: get, set, delete
  - examples
    - Client-side caches
      - Browser local storage
      - impossible for your servers to remove/invalidate cached objects directly
    - Caches Co-located with Code
      - local cache
        - faster
        - cannot be invalidated easily across multiple instances
      - distributed cache
        - By adding servers, you can scale both the throughput and overall memory pool of your cache
        - cache invalidation is easier
          - efficiently remove objects from the cache, allowing for cache invalidation on source data changes
          - in some cases, you need to remove objects from cache as soon as the data changes
        - scaling
          - add more servers, use consistent hashing to avoid moving/deleting most data
          - data replication
          - combine data replication with data partitioning
- Caching rules of thumb
  - the higher up the call stack you can cache, the more resources you can save
  - Caching objects that are never requested again is simply a waste of time and resources
  - If it is not possible to cache entire pages, maybe it is possible to cache page fragments or use some other trick to reduce the number of possible cache keys
  - **the point** you need to maximize the cache hit ratio, and you can only do it by
    - increasing your cache pool
    - extending the TTL of your objects
    - decreasing the number of potential cache keys.
  - **where to start?**
    - simple metric to define **potential gain from caching**
      - aggregated time spent per page = response time per request \* (times) number of requests
  - Cache invalidation is hard
    - cached objects are usually a result of computation that takes multiple data sources as its input
    - consider caching partial results and going to the data source for the missing “critical” information
    - recommendation: avoid cache invalidation altogether for as long as possible and using TTL-based expiration instead. In most cases, short TTL or a hybrid solution, where you load critical data on the fly, is enough to satisfy the business needs.
